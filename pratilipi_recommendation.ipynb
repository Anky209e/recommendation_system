{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading User interaction Dataset as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pratilipi_id</th>\n",
       "      <th>read_percent</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5506791961876448</td>\n",
       "      <td>1377786228262109</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-22 10:29:57.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5506791971543560</td>\n",
       "      <td>1377786223038206</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2022-03-19 13:49:25.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5506791996468218</td>\n",
       "      <td>1377786227025240</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-21 17:28:47.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5506791978752866</td>\n",
       "      <td>1377786222398208</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2022-03-21 07:39:25.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5506791978962946</td>\n",
       "      <td>1377786228157051</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-22 17:32:44.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>5506791965506371</td>\n",
       "      <td>1377786228243175</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-19 04:37:10.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>5506791966125995</td>\n",
       "      <td>1377786221431279</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-21 17:24:46.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>5506791964496442</td>\n",
       "      <td>1377786226829597</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-22 08:04:29.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>5506791968781083</td>\n",
       "      <td>1377786226056467</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-21 06:41:54.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>5506791956021363</td>\n",
       "      <td>1377786226666757</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-20 08:59:49.346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id      pratilipi_id  read_percent  \\\n",
       "0        5506791961876448  1377786228262109         100.0   \n",
       "1        5506791971543560  1377786223038206          40.0   \n",
       "2        5506791996468218  1377786227025240         100.0   \n",
       "3        5506791978752866  1377786222398208          65.0   \n",
       "4        5506791978962946  1377786228157051         100.0   \n",
       "...                   ...               ...           ...   \n",
       "2499995  5506791965506371  1377786228243175         100.0   \n",
       "2499996  5506791966125995  1377786221431279         100.0   \n",
       "2499997  5506791964496442  1377786226829597         100.0   \n",
       "2499998  5506791968781083  1377786226056467         100.0   \n",
       "2499999  5506791956021363  1377786226666757         100.0   \n",
       "\n",
       "                      updated_at  \n",
       "0        2022-03-22 10:29:57.291  \n",
       "1        2022-03-19 13:49:25.660  \n",
       "2        2022-03-21 17:28:47.288  \n",
       "3        2022-03-21 07:39:25.183  \n",
       "4        2022-03-22 17:32:44.777  \n",
       "...                          ...  \n",
       "2499995  2022-03-19 04:37:10.568  \n",
       "2499996  2022-03-21 17:24:46.089  \n",
       "2499997  2022-03-22 08:04:29.219  \n",
       "2499998  2022-03-21 06:41:54.083  \n",
       "2499999  2022-03-20 08:59:49.346  \n",
       "\n",
       "[2500000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction_df = pd.read_csv(\"data/user_interaction.csv\")\n",
    "user_interaction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading metadata as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>pratilipi_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3418949279741297</td>\n",
       "      <td>1025741862639304</td>\n",
       "      <td>translation</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-19 15:26:13</td>\n",
       "      <td>2016-09-30 10:37:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2270332351871840</td>\n",
       "      <td>1377786215601277</td>\n",
       "      <td>translation</td>\n",
       "      <td>171</td>\n",
       "      <td>2021-01-21 16:27:07</td>\n",
       "      <td>2018-06-11 13:17:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2270332352037261</td>\n",
       "      <td>1377786215601962</td>\n",
       "      <td>translation</td>\n",
       "      <td>92</td>\n",
       "      <td>2020-09-29 12:33:57</td>\n",
       "      <td>2018-06-12 04:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2270332352521845</td>\n",
       "      <td>1377786215640994</td>\n",
       "      <td>translation</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-17 09:03:37</td>\n",
       "      <td>2019-09-26 14:58:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2270332349665658</td>\n",
       "      <td>1377786215931338</td>\n",
       "      <td>translation</td>\n",
       "      <td>47</td>\n",
       "      <td>2020-05-05 11:33:41</td>\n",
       "      <td>2018-11-25 12:28:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954496</th>\n",
       "      <td>-2270332337845247</td>\n",
       "      <td>1377786228358627</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>304</td>\n",
       "      <td>2022-03-22 17:40:22</td>\n",
       "      <td>2022-03-22 17:40:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954497</th>\n",
       "      <td>-2270332334263077</td>\n",
       "      <td>1377786228362002</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>588</td>\n",
       "      <td>2022-03-22 11:44:39</td>\n",
       "      <td>2022-03-22 11:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954498</th>\n",
       "      <td>-2270332350350076</td>\n",
       "      <td>1377786228362682</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>359</td>\n",
       "      <td>2022-03-22 12:39:41</td>\n",
       "      <td>2022-03-22 12:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954499</th>\n",
       "      <td>-2270332337845247</td>\n",
       "      <td>1377786228375726</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>310</td>\n",
       "      <td>2022-03-23 15:55:11</td>\n",
       "      <td>2022-03-23 15:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954500</th>\n",
       "      <td>-2270332334263077</td>\n",
       "      <td>1377786228376825</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>534</td>\n",
       "      <td>2022-03-23 10:52:43</td>\n",
       "      <td>2022-03-23 10:52:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954501 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id      pratilipi_id    category_name  reading_time  \\\n",
       "0      -3418949279741297  1025741862639304      translation             0   \n",
       "1      -2270332351871840  1377786215601277      translation           171   \n",
       "2      -2270332352037261  1377786215601962      translation            92   \n",
       "3      -2270332352521845  1377786215640994      translation             0   \n",
       "4      -2270332349665658  1377786215931338      translation            47   \n",
       "...                  ...               ...              ...           ...   \n",
       "954496 -2270332337845247  1377786228358627  Horror-Marathon           304   \n",
       "954497 -2270332334263077  1377786228362002  Horror-Marathon           588   \n",
       "954498 -2270332350350076  1377786228362682  Horror-Marathon           359   \n",
       "954499 -2270332337845247  1377786228375726  Horror-Marathon           310   \n",
       "954500 -2270332334263077  1377786228376825  Horror-Marathon           534   \n",
       "\n",
       "                 updated_at         published_at  \n",
       "0       2020-08-19 15:26:13  2016-09-30 10:37:04  \n",
       "1       2021-01-21 16:27:07  2018-06-11 13:17:48  \n",
       "2       2020-09-29 12:33:57  2018-06-12 04:19:12  \n",
       "3       2019-10-17 09:03:37  2019-09-26 14:58:53  \n",
       "4       2020-05-05 11:33:41  2018-11-25 12:28:23  \n",
       "...                     ...                  ...  \n",
       "954496  2022-03-22 17:40:22  2022-03-22 17:40:22  \n",
       "954497  2022-03-22 11:44:39  2022-03-22 11:44:39  \n",
       "954498  2022-03-22 12:39:41  2022-03-22 12:38:40  \n",
       "954499  2022-03-23 15:55:11  2022-03-23 15:55:11  \n",
       "954500  2022-03-23 10:52:43  2022-03-23 10:52:42  \n",
       "\n",
       "[954501 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"data/metadata.csv\")\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interaction_df['updated_at'] = pd.to_datetime(user_interaction_df['updated_at'])\n",
    "metadata_df['updated_at'] = pd.to_datetime(metadata_df['updated_at'])\n",
    "metadata_df['published_at'] = pd.to_datetime(metadata_df['published_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pratilipi_id</th>\n",
       "      <th>read_percent</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033131</th>\n",
       "      <td>5506791954036110</td>\n",
       "      <td>1377786225804654</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-18 15:14:41.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415300</th>\n",
       "      <td>5506791980439899</td>\n",
       "      <td>1377786228150074</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-18 15:14:42.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318259</th>\n",
       "      <td>5506791979182708</td>\n",
       "      <td>1377786218415632</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-18 15:14:42.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952322</th>\n",
       "      <td>5506791996330389</td>\n",
       "      <td>1377786219497547</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-18 15:14:42.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114134</th>\n",
       "      <td>5506791961370166</td>\n",
       "      <td>1377786224952303</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-18 15:14:42.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624343</th>\n",
       "      <td>5506791959874343</td>\n",
       "      <td>1377786225302354</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2022-03-23 00:08:09.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446414</th>\n",
       "      <td>5506791959279525</td>\n",
       "      <td>1377786225901639</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-23 00:08:16.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561039</th>\n",
       "      <td>5506791996088677</td>\n",
       "      <td>1377786223947072</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2022-03-23 00:08:22.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426598</th>\n",
       "      <td>5506791980825783</td>\n",
       "      <td>1377786227076616</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-23 00:08:24.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186369</th>\n",
       "      <td>5506791988747277</td>\n",
       "      <td>1377786224767880</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2022-03-23 00:08:25.306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id      pratilipi_id  read_percent  \\\n",
       "1033131  5506791954036110  1377786225804654         100.0   \n",
       "1415300  5506791980439899  1377786228150074         100.0   \n",
       "2318259  5506791979182708  1377786218415632         100.0   \n",
       "952322   5506791996330389  1377786219497547         100.0   \n",
       "2114134  5506791961370166  1377786224952303         100.0   \n",
       "...                   ...               ...           ...   \n",
       "624343   5506791959874343  1377786225302354          99.0   \n",
       "446414   5506791959279525  1377786225901639         100.0   \n",
       "561039   5506791996088677  1377786223947072          84.0   \n",
       "426598   5506791980825783  1377786227076616         100.0   \n",
       "2186369  5506791988747277  1377786224767880         100.0   \n",
       "\n",
       "                     updated_at  \n",
       "1033131 2022-03-18 15:14:41.827  \n",
       "1415300 2022-03-18 15:14:42.120  \n",
       "2318259 2022-03-18 15:14:42.134  \n",
       "952322  2022-03-18 15:14:42.170  \n",
       "2114134 2022-03-18 15:14:42.282  \n",
       "...                         ...  \n",
       "624343  2022-03-23 00:08:09.845  \n",
       "446414  2022-03-23 00:08:16.603  \n",
       "561039  2022-03-23 00:08:22.177  \n",
       "426598  2022-03-23 00:08:24.364  \n",
       "2186369 2022-03-23 00:08:25.306  \n",
       "\n",
       "[2500000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction_df  = user_interaction_df.sort_values('updated_at')\n",
    "user_interaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>pratilipi_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3418949279741297</td>\n",
       "      <td>1025741862639304</td>\n",
       "      <td>translation</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-08-19 15:26:13</td>\n",
       "      <td>2016-09-30 10:37:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2270332351871840</td>\n",
       "      <td>1377786215601277</td>\n",
       "      <td>translation</td>\n",
       "      <td>171</td>\n",
       "      <td>2021-01-21 16:27:07</td>\n",
       "      <td>2018-06-11 13:17:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2270332352037261</td>\n",
       "      <td>1377786215601962</td>\n",
       "      <td>translation</td>\n",
       "      <td>92</td>\n",
       "      <td>2020-09-29 12:33:57</td>\n",
       "      <td>2018-06-12 04:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2270332352521845</td>\n",
       "      <td>1377786215640994</td>\n",
       "      <td>translation</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-17 09:03:37</td>\n",
       "      <td>2019-09-26 14:58:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2270332349665658</td>\n",
       "      <td>1377786215931338</td>\n",
       "      <td>translation</td>\n",
       "      <td>47</td>\n",
       "      <td>2020-05-05 11:33:41</td>\n",
       "      <td>2018-11-25 12:28:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954496</th>\n",
       "      <td>-2270332337845247</td>\n",
       "      <td>1377786228358627</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>304</td>\n",
       "      <td>2022-03-22 17:40:22</td>\n",
       "      <td>2022-03-22 17:40:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954497</th>\n",
       "      <td>-2270332334263077</td>\n",
       "      <td>1377786228362002</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>588</td>\n",
       "      <td>2022-03-22 11:44:39</td>\n",
       "      <td>2022-03-22 11:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954498</th>\n",
       "      <td>-2270332350350076</td>\n",
       "      <td>1377786228362682</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>359</td>\n",
       "      <td>2022-03-22 12:39:41</td>\n",
       "      <td>2022-03-22 12:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954499</th>\n",
       "      <td>-2270332337845247</td>\n",
       "      <td>1377786228375726</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>310</td>\n",
       "      <td>2022-03-23 15:55:11</td>\n",
       "      <td>2022-03-23 15:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954500</th>\n",
       "      <td>-2270332334263077</td>\n",
       "      <td>1377786228376825</td>\n",
       "      <td>Horror-Marathon</td>\n",
       "      <td>534</td>\n",
       "      <td>2022-03-23 10:52:43</td>\n",
       "      <td>2022-03-23 10:52:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954501 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id      pratilipi_id    category_name  reading_time  \\\n",
       "0      -3418949279741297  1025741862639304      translation             0   \n",
       "1      -2270332351871840  1377786215601277      translation           171   \n",
       "2      -2270332352037261  1377786215601962      translation            92   \n",
       "3      -2270332352521845  1377786215640994      translation             0   \n",
       "4      -2270332349665658  1377786215931338      translation            47   \n",
       "...                  ...               ...              ...           ...   \n",
       "954496 -2270332337845247  1377786228358627  Horror-Marathon           304   \n",
       "954497 -2270332334263077  1377786228362002  Horror-Marathon           588   \n",
       "954498 -2270332350350076  1377786228362682  Horror-Marathon           359   \n",
       "954499 -2270332337845247  1377786228375726  Horror-Marathon           310   \n",
       "954500 -2270332334263077  1377786228376825  Horror-Marathon           534   \n",
       "\n",
       "                updated_at        published_at  \n",
       "0      2020-08-19 15:26:13 2016-09-30 10:37:04  \n",
       "1      2021-01-21 16:27:07 2018-06-11 13:17:48  \n",
       "2      2020-09-29 12:33:57 2018-06-12 04:19:12  \n",
       "3      2019-10-17 09:03:37 2019-09-26 14:58:53  \n",
       "4      2020-05-05 11:33:41 2018-11-25 12:28:23  \n",
       "...                    ...                 ...  \n",
       "954496 2022-03-22 17:40:22 2022-03-22 17:40:22  \n",
       "954497 2022-03-22 11:44:39 2022-03-22 11:44:39  \n",
       "954498 2022-03-22 12:39:41 2022-03-22 12:38:40  \n",
       "954499 2022-03-23 15:55:11 2022-03-23 15:55:11  \n",
       "954500 2022-03-23 10:52:43 2022-03-23 10:52:42  \n",
       "\n",
       "[954501 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating user and item mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = dict(enumerate(user_interaction_df['user_id'].unique()))\n",
    "user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "\n",
    "item_mapping = dict(enumerate(user_interaction_df['pratilipi_id'].unique()))\n",
    "item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "\n",
    "user_indices = [user_mapping[user] for user in user_interaction_df['user_id']]\n",
    "item_indices = [item_mapping[item] for item in user_interaction_df['pratilipi_id']]\n",
    "\n",
    "ratings = user_interaction_df['read_percent'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadingDataset(Dataset):\n",
    "    def __init__(self,user_indices,item_indices,ratings):\n",
    "        self.user_indices = torch.tensor(user_indices,dtype=torch.long)\n",
    "        self.item_indices = torch.tensor(item_indices,dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings,dtype=torch.float)/100 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.user_indices[index],\n",
    "            self.item_indices[index],\n",
    "            self.ratings[index]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*aP-Mx266ExwoWZPSdHtYpA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCollaborativeFilter(nn.Module):\n",
    "    \"\"\"\n",
    "        Neural Collaborative Filtering\\n\n",
    "        Inputs: num_users, num_items, embedding_dim=100\n",
    "    \"\"\"\n",
    "    def __init__(self,num_users,num_items,embedding_dim=100):\n",
    "       \n",
    "        super(NeuralCollaborativeFilter,self).__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users,embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items,embedding_dim)\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,user_input,item_input):\n",
    "        x = self.user_embedding(user_input)\n",
    "        y = self.user_embedding(item_input)\n",
    "\n",
    "        input_vector = torch.cat([x,y],dim=1)\n",
    "        preds = self.network(input_vector)\n",
    "        return preds.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_dataloader,device):\n",
    "    \"\"\"Evaluates Model\\n Returns batch_loss\"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.MSELoss()\n",
    "    batch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for users,items,ratings in test_dataloader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "            preds = model(users,items)\n",
    "            loss = criterion(preds,ratings)\n",
    "            batch_loss += loss.item()\n",
    "    return batch_loss/len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.75 * len(user_indices))\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ReadingDataset(\n",
    "    user_indices[:train_size],\n",
    "    item_indices[:train_size],\n",
    "    ratings[:train_size]\n",
    ")\n",
    "val_dataset = ReadingDataset(\n",
    "    user_indices[train_size:],\n",
    "    item_indices[train_size:],\n",
    "    ratings[train_size:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "LR = 0.001\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralCollaborativeFilter(\n",
       "  (user_embedding): Embedding(243606, 100)\n",
       "  (item_embedding): Embedding(241405, 100)\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralCollaborativeFilter(num_users,num_items)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "         model,\n",
    "         train_loader,\n",
    "         val_loader,\n",
    "         EPOCHS,\n",
    "         LR,\n",
    "         DEVICE\n",
    "         ):\n",
    "     model = model.to(DEVICE)\n",
    "     criterion = nn.MSELoss()\n",
    "     optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LR,\n",
    "        weight_decay = 1e-5\n",
    "     )\n",
    "     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',patience=2)\n",
    "     max_loss = float('inf')\n",
    "\n",
    "     for epoch in range(EPOCHS):\n",
    "          model.train()\n",
    "          train_loss = 0\n",
    "          for batch_idx, (users, items, ratings) in enumerate(train_loader):\n",
    "               users = users.to(DEVICE)\n",
    "               items = items.to(DEVICE)\n",
    "               ratings = ratings.to(DEVICE)\n",
    "\n",
    "               predictions = model(users, items)\n",
    "               loss = criterion(predictions, ratings)\n",
    "\n",
    "               optimizer.zero_grad()\n",
    "               loss.backward()\n",
    "               torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "               optimizer.step()\n",
    "\n",
    "               train_loss += loss.item()\n",
    "\n",
    "               if batch_idx % 100 == 0:\n",
    "                    print(\n",
    "                    f'Epoch {epoch+1}/{EPOCHS} - Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}')\n",
    "     \n",
    "     val_loss = evaluate_model(model, val_loader, DEVICE)\n",
    "     scheduler.step(val_loss)\n",
    "\n",
    "     print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "     print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "     print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "     if val_loss < max_loss:\n",
    "          max_loss = val_loss\n",
    "          torch.save(model.state_dict(), 'ncf_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Batch 0/7325 - Loss: 0.2487\n",
      "Epoch 1/1 - Batch 100/7325 - Loss: 0.0448\n",
      "Epoch 1/1 - Batch 200/7325 - Loss: 0.0388\n",
      "Epoch 1/1 - Batch 300/7325 - Loss: 0.0593\n",
      "Epoch 1/1 - Batch 400/7325 - Loss: 0.0483\n",
      "Epoch 1/1 - Batch 500/7325 - Loss: 0.0454\n",
      "Epoch 1/1 - Batch 600/7325 - Loss: 0.0472\n",
      "Epoch 1/1 - Batch 700/7325 - Loss: 0.0599\n",
      "Epoch 1/1 - Batch 800/7325 - Loss: 0.0355\n",
      "Epoch 1/1 - Batch 900/7325 - Loss: 0.0497\n",
      "Epoch 1/1 - Batch 1000/7325 - Loss: 0.0397\n",
      "Epoch 1/1 - Batch 1100/7325 - Loss: 0.0567\n",
      "Epoch 1/1 - Batch 1200/7325 - Loss: 0.0438\n",
      "Epoch 1/1 - Batch 1300/7325 - Loss: 0.0417\n",
      "Epoch 1/1 - Batch 1400/7325 - Loss: 0.0363\n",
      "Epoch 1/1 - Batch 1500/7325 - Loss: 0.0437\n",
      "Epoch 1/1 - Batch 1600/7325 - Loss: 0.0525\n",
      "Epoch 1/1 - Batch 1700/7325 - Loss: 0.0506\n",
      "Epoch 1/1 - Batch 1800/7325 - Loss: 0.0585\n",
      "Epoch 1/1 - Batch 1900/7325 - Loss: 0.0234\n",
      "Epoch 1/1 - Batch 2000/7325 - Loss: 0.0580\n",
      "Epoch 1/1 - Batch 2100/7325 - Loss: 0.0519\n",
      "Epoch 1/1 - Batch 2200/7325 - Loss: 0.0285\n",
      "Epoch 1/1 - Batch 2300/7325 - Loss: 0.0329\n",
      "Epoch 1/1 - Batch 2400/7325 - Loss: 0.0296\n",
      "Epoch 1/1 - Batch 2500/7325 - Loss: 0.0506\n",
      "Epoch 1/1 - Batch 2600/7325 - Loss: 0.0499\n",
      "Epoch 1/1 - Batch 2700/7325 - Loss: 0.0418\n",
      "Epoch 1/1 - Batch 2800/7325 - Loss: 0.0452\n",
      "Epoch 1/1 - Batch 2900/7325 - Loss: 0.0436\n",
      "Epoch 1/1 - Batch 3000/7325 - Loss: 0.0477\n",
      "Epoch 1/1 - Batch 3100/7325 - Loss: 0.0346\n",
      "Epoch 1/1 - Batch 3200/7325 - Loss: 0.0496\n",
      "Epoch 1/1 - Batch 3300/7325 - Loss: 0.0438\n",
      "Epoch 1/1 - Batch 3400/7325 - Loss: 0.0422\n",
      "Epoch 1/1 - Batch 3500/7325 - Loss: 0.0555\n",
      "Epoch 1/1 - Batch 3600/7325 - Loss: 0.0412\n",
      "Epoch 1/1 - Batch 3700/7325 - Loss: 0.0453\n",
      "Epoch 1/1 - Batch 3800/7325 - Loss: 0.0454\n",
      "Epoch 1/1 - Batch 3900/7325 - Loss: 0.0437\n",
      "Epoch 1/1 - Batch 4000/7325 - Loss: 0.0228\n",
      "Epoch 1/1 - Batch 4100/7325 - Loss: 0.0361\n",
      "Epoch 1/1 - Batch 4200/7325 - Loss: 0.0544\n",
      "Epoch 1/1 - Batch 4300/7325 - Loss: 0.0515\n",
      "Epoch 1/1 - Batch 4400/7325 - Loss: 0.0460\n",
      "Epoch 1/1 - Batch 4500/7325 - Loss: 0.0378\n",
      "Epoch 1/1 - Batch 4600/7325 - Loss: 0.0339\n",
      "Epoch 1/1 - Batch 4700/7325 - Loss: 0.0318\n",
      "Epoch 1/1 - Batch 4800/7325 - Loss: 0.0524\n",
      "Epoch 1/1 - Batch 4900/7325 - Loss: 0.0584\n",
      "Epoch 1/1 - Batch 5000/7325 - Loss: 0.0308\n",
      "Epoch 1/1 - Batch 5100/7325 - Loss: 0.0579\n",
      "Epoch 1/1 - Batch 5200/7325 - Loss: 0.0442\n",
      "Epoch 1/1 - Batch 5300/7325 - Loss: 0.0486\n",
      "Epoch 1/1 - Batch 5400/7325 - Loss: 0.0335\n",
      "Epoch 1/1 - Batch 5500/7325 - Loss: 0.0499\n",
      "Epoch 1/1 - Batch 5600/7325 - Loss: 0.0475\n",
      "Epoch 1/1 - Batch 5700/7325 - Loss: 0.0340\n",
      "Epoch 1/1 - Batch 5800/7325 - Loss: 0.0329\n",
      "Epoch 1/1 - Batch 5900/7325 - Loss: 0.0503\n",
      "Epoch 1/1 - Batch 6000/7325 - Loss: 0.0376\n",
      "Epoch 1/1 - Batch 6100/7325 - Loss: 0.0543\n",
      "Epoch 1/1 - Batch 6200/7325 - Loss: 0.0301\n",
      "Epoch 1/1 - Batch 6300/7325 - Loss: 0.0402\n",
      "Epoch 1/1 - Batch 6400/7325 - Loss: 0.0329\n",
      "Epoch 1/1 - Batch 6500/7325 - Loss: 0.0485\n",
      "Epoch 1/1 - Batch 6600/7325 - Loss: 0.0560\n",
      "Epoch 1/1 - Batch 6700/7325 - Loss: 0.0252\n",
      "Epoch 1/1 - Batch 6800/7325 - Loss: 0.0469\n",
      "Epoch 1/1 - Batch 6900/7325 - Loss: 0.0332\n",
      "Epoch 1/1 - Batch 7000/7325 - Loss: 0.0561\n",
      "Epoch 1/1 - Batch 7100/7325 - Loss: 0.0449\n",
      "Epoch 1/1 - Batch 7200/7325 - Loss: 0.0376\n",
      "Epoch 1/1 - Batch 7300/7325 - Loss: 0.0519\n",
      "Epoch 1/1:\n",
      "Training Loss: 0.0443\n",
      "Validation Loss: 0.0467\n"
     ]
    }
   ],
   "source": [
    "train(model=model,train_loader=train_loader,val_loader=val_loader,EPOCHS=EPOCHS,LR=LR,DEVICE=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model,user_id,num_recommendations,device):\n",
    "    \"\"\"\n",
    "    Return recommendations for a user id\\n\n",
    "    Input : model,user_id,num_recommendations,device\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    recommendations = []\n",
    "    with torch.no_grad():\n",
    "        user_index = user_mapping[user_id]\n",
    "        user_input = torch.tensor([user_index],dtype=torch.long,device=device)\n",
    "        items_list = list(item_mapping.values())\n",
    "        items_input = torch.tensor(items_list,dtype=torch.long,device=device)\n",
    "\n",
    "        user_input = user_input.expand(len(items_input))\n",
    "\n",
    "        preds = model(user_input,items_input)\n",
    "\n",
    "        top_recommendations = torch.topk(preds,num_recommendations)\n",
    "        reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "        \n",
    "        for i in top_recommendations.indices:\n",
    "            recommendations.append(reverse_item_mapping[i.item()])\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(user_id,num_user,num_items,weight_path,device):\n",
    "    model = NeuralCollaborativeFilter(num_users=num_user,num_items=num_items)\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model.to(device)\n",
    "    recommendations = get_recommendations(model,user_id,num_recommendations=5,device=device)\n",
    "    print(\"----- Recommended Pratilipis -----\\n\")\n",
    "    for r in recommendations:\n",
    "        print(f\"ID:{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Recommended Pratilipis -----\n",
      "\n",
      "ID:1377786228240538\n",
      "ID:1377786228211516\n",
      "ID:1377786228204335\n",
      "ID:1377786226447185\n",
      "ID:1377786228253938\n"
     ]
    }
   ],
   "source": [
    "user_id = 5506791961876448\n",
    "inference(user_id=user_id,num_user=num_users,num_items=num_items,weight_path=\"ncf_weights.pth\",device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
